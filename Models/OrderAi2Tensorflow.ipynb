{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Utente\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.1\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import copy\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import fetch_california_housing, make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "housing = fetch_california_housing()\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'  \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(housing.data, housing.target, test_size=0.98, random_state=2)\n",
    "XR, yR = make_regression(n_samples=100, n_features=2, noise=0, random_state=5)\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(XR, yR, test_size=0.20, random_state=2)\n",
    "\n",
    "def normalize_dataset(X):\n",
    "    return tf.keras.utils.normalize(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"C:\\Users\\Utente\\AppData\\Local\\Temp\\ipykernel_21264\\3358911384.py\", line 69, in train_step  *\n        X = layer(X)\n    File \"C:\\Users\\Utente\\AppData\\Local\\Temp\\ipykernel_21264\\3358911384.py\", line 24, in __call__  *\n        z = tf.add(tf.keras.layers.dot([X, self.weights], axes=0), self.bias)\n    File \"c:\\Users\\Utente\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\layers\\merging\\dot.py\", line 226, in dot  **\n        return Dot(axes=axes, normalize=normalize, **kwargs)(inputs)\n    File \"c:\\Users\\Utente\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"c:\\Users\\Utente\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\layers\\merging\\dot.py\", line 136, in build\n        raise ValueError(\n\n    ValueError: Incompatible input shapes: axis values 412 (at axis 0) != 8 (at axis 0). Full input shapes: (412, 8), (8, 10)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 96\u001b[0m\n\u001b[0;32m     85\u001b[0m         \u001b[39mprint\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpredicted)\n\u001b[0;32m     87\u001b[0m model \u001b[39m=\u001b[39m MLPLinearRegressor([\n\u001b[0;32m     88\u001b[0m     Layer(neurons\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m,),\n\u001b[0;32m     89\u001b[0m     Layer(neurons\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     92\u001b[0m     Layer(neurons\u001b[39m=\u001b[39mX_train\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m], )\n\u001b[0;32m     93\u001b[0m ],X_train, tf\u001b[39m.\u001b[39msqueeze(y_train), lr\u001b[39m=\u001b[39m\u001b[39m0.001\u001b[39m, epochs\u001b[39m=\u001b[39m\u001b[39m100\u001b[39m)\n\u001b[1;32m---> 96\u001b[0m model\u001b[39m.\u001b[39;49mtrain()\n\u001b[0;32m     97\u001b[0m model\u001b[39m.\u001b[39mcalc_metrics()\n\u001b[0;32m    100\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mMeanSquaredError: \u001b[39m\u001b[39m\"\u001b[39m, model\u001b[39m.\u001b[39mmse\u001b[39m.\u001b[39mresult()\u001b[39m.\u001b[39mnumpy())\n",
      "Cell \u001b[1;32mIn[28], line 73\u001b[0m, in \u001b[0;36mMLPLinearRegressor.train\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtrain\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m---> 73\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mweights \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mtrain_step(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mXN)\n\u001b[0;32m     74\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvars \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayers[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mweights, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayers[\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mweights, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayers[\u001b[39m2\u001b[39m]\u001b[39m.\u001b[39mweights,\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayers[\u001b[39m3\u001b[39m]\u001b[39m.\u001b[39mweights,\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayers[\u001b[39m4\u001b[39m]\u001b[39m.\u001b[39mweights, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayers[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mbias, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayers[\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mbias, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayers[\u001b[39m2\u001b[39m]\u001b[39m.\u001b[39mbias,\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayers[\u001b[39m3\u001b[39m]\u001b[39m.\u001b[39mbias,\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayers[\u001b[39m4\u001b[39m]\u001b[39m.\u001b[39mbias]\n\u001b[0;32m     76\u001b[0m     \u001b[39mfor\u001b[39;00m e \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mepochs):\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m--> 153\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m    154\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    155\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_filewfzno_z4.py:23\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_step\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m     21\u001b[0m     X \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(layer), (ag__\u001b[39m.\u001b[39mld(X),), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[0;32m     22\u001b[0m layer \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mUndefined(\u001b[39m'\u001b[39m\u001b[39mlayer\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m---> 23\u001b[0m ag__\u001b[39m.\u001b[39mfor_stmt(ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39mlayers, \u001b[39mNone\u001b[39;00m, loop_body, get_state, set_state, (\u001b[39m'\u001b[39m\u001b[39mX\u001b[39m\u001b[39m'\u001b[39m,), {\u001b[39m'\u001b[39m\u001b[39miterate_names\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m'\u001b[39m\u001b[39mlayer\u001b[39m\u001b[39m'\u001b[39m})\n\u001b[0;32m     24\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     25\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_filewfzno_z4.py:21\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_step.<locals>.loop_body\u001b[1;34m(itr)\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[39mnonlocal\u001b[39;00m X\n\u001b[0;32m     20\u001b[0m layer \u001b[39m=\u001b[39m itr\n\u001b[1;32m---> 21\u001b[0m X \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39;49mconverted_call(ag__\u001b[39m.\u001b[39;49mld(layer), (ag__\u001b[39m.\u001b[39;49mld(X),), \u001b[39mNone\u001b[39;49;00m, fscope)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_filenetvnkxg.py:27\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf____call__\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m     25\u001b[0m n_features \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mUndefined(\u001b[39m'\u001b[39m\u001b[39mn_features\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     26\u001b[0m ag__\u001b[39m.\u001b[39mif_stmt(ag__\u001b[39m.\u001b[39mnot_(ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39mbuild), if_body, else_body, get_state, set_state, (\u001b[39m'\u001b[39m\u001b[39mself.bias\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mself.build\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mself.weights\u001b[39m\u001b[39m'\u001b[39m), \u001b[39m3\u001b[39m)\n\u001b[1;32m---> 27\u001b[0m z \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(tf)\u001b[39m.\u001b[39madd, (ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(tf)\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mlayers\u001b[39m.\u001b[39mdot, ([ag__\u001b[39m.\u001b[39mld(X), ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39mweights],), \u001b[39mdict\u001b[39m(axes\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m), fscope), ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39mbias), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[0;32m     28\u001b[0m ag__\u001b[39m.\u001b[39mld(\u001b[39mprint\u001b[39m)(ag__\u001b[39m.\u001b[39mld(X)\u001b[39m.\u001b[39mshape, \u001b[39m'\u001b[39m\u001b[39m*\u001b[39m\u001b[39m'\u001b[39m, ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39mweights\u001b[39m.\u001b[39mshape, \u001b[39m'\u001b[39m\u001b[39m+\u001b[39m\u001b[39m'\u001b[39m, ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39mbias\u001b[39m.\u001b[39mshape, \u001b[39m'\u001b[39m\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m, ag__\u001b[39m.\u001b[39mld(z)\u001b[39m.\u001b[39mshape)\n\u001b[0;32m     29\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Utente\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\layers\\merging\\dot.py:226\u001b[0m, in \u001b[0;36mdot\u001b[1;34m(inputs, axes, normalize, **kwargs)\u001b[0m\n\u001b[0;32m    209\u001b[0m \u001b[39m@keras_export\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mkeras.layers.dot\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    210\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdot\u001b[39m(inputs, axes, normalize\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    211\u001b[0m     \u001b[39m\"\"\"Functional interface to the `Dot` layer.\u001b[39;00m\n\u001b[0;32m    212\u001b[0m \n\u001b[0;32m    213\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    224\u001b[0m \u001b[39m        A tensor, the dot product of the samples from the inputs.\u001b[39;00m\n\u001b[0;32m    225\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 226\u001b[0m     \u001b[39mreturn\u001b[39;00m Dot(axes\u001b[39m=\u001b[39;49maxes, normalize\u001b[39m=\u001b[39;49mnormalize, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)(inputs)\n",
      "File \u001b[1;32mc:\\Users\\Utente\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\Utente\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\layers\\merging\\dot.py:136\u001b[0m, in \u001b[0;36mDot.build\u001b[1;34m(self, input_shape)\u001b[0m\n\u001b[0;32m    134\u001b[0m     axes \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxes\n\u001b[0;32m    135\u001b[0m \u001b[39mif\u001b[39;00m shape1[axes[\u001b[39m0\u001b[39m]] \u001b[39m!=\u001b[39m shape2[axes[\u001b[39m1\u001b[39m]]:\n\u001b[1;32m--> 136\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    137\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mIncompatible input shapes: \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    138\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39maxis values \u001b[39m\u001b[39m{\u001b[39;00mshape1[axes[\u001b[39m0\u001b[39m]]\u001b[39m}\u001b[39;00m\u001b[39m (at axis \u001b[39m\u001b[39m{\u001b[39;00maxes[\u001b[39m0\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m) != \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    139\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mshape2[axes[\u001b[39m1\u001b[39m]]\u001b[39m}\u001b[39;00m\u001b[39m (at axis \u001b[39m\u001b[39m{\u001b[39;00maxes[\u001b[39m1\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m). \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    140\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mFull input shapes: \u001b[39m\u001b[39m{\u001b[39;00mshape1\u001b[39m}\u001b[39;00m\u001b[39m, \u001b[39m\u001b[39m{\u001b[39;00mshape2\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    141\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"C:\\Users\\Utente\\AppData\\Local\\Temp\\ipykernel_21264\\3358911384.py\", line 69, in train_step  *\n        X = layer(X)\n    File \"C:\\Users\\Utente\\AppData\\Local\\Temp\\ipykernel_21264\\3358911384.py\", line 24, in __call__  *\n        z = tf.add(tf.keras.layers.dot([X, self.weights], axes=0), self.bias)\n    File \"c:\\Users\\Utente\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\layers\\merging\\dot.py\", line 226, in dot  **\n        return Dot(axes=axes, normalize=normalize, **kwargs)(inputs)\n    File \"c:\\Users\\Utente\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"c:\\Users\\Utente\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\layers\\merging\\dot.py\", line 136, in build\n        raise ValueError(\n\n    ValueError: Incompatible input shapes: axis values 412 (at axis 0) != 8 (at axis 0). Full input shapes: (412, 8), (8, 10)\n"
     ]
    }
   ],
   "source": [
    "class Layer(tf.Module):\n",
    "    def __init__(self, neurons=30, activation=tf.identity):\n",
    "        self.neurons = neurons\n",
    "        self.activation = activation\n",
    "        self.build = False\n",
    "        self.normalized = False\n",
    "\n",
    "    @tf.function(reduce_retracing=True)\n",
    "    def xavier_init(self, shape):\n",
    "        in_dim, out_dim = shape\n",
    "        xavier_lim = tf.sqrt(6.)/tf.sqrt(tf.cast(in_dim + out_dim, tf.float32))\n",
    "        weight_vals = tf.cast(tf.random.uniform(shape=(in_dim, out_dim), \n",
    "                                        minval=-xavier_lim, maxval=xavier_lim, seed=22, dtype=tf.float32), dtype=tf.double)\n",
    "        return weight_vals\n",
    "\n",
    "    @tf.function\n",
    "    def __call__(self, X):\n",
    "        if not self.build:\n",
    "            n_features = X.shape[1]\n",
    "            self.weights = tf.Variable(self.xavier_init(shape=(n_features, self.neurons)), name=\"Weights\", dtype=tf.double, trainable=True )\n",
    "            self.bias = tf.Variable(tf.zeros(shape=1, dtype=tf.double), name=\"Bias\", dtype=tf.double, trainable=True )\n",
    "            self.build = True\n",
    "\n",
    "        z = tf.add(tf.keras.layers.dot([X, self.weights], axes=0), self.bias)\n",
    "\n",
    "        print(X.shape,\"*\",self.weights.shape,\"+\",self.bias.shape, \"=\", z.shape)\n",
    "        return self.activation(z)\n",
    "\n",
    "    \n",
    "\n",
    "class MLPLinearRegressor(tf.Module):\n",
    "    def __init__(self, layers, X, y, lr=0.001, epochs=10):\n",
    "        self.layers = layers\n",
    "        self.lr = lr\n",
    "        self.epochs = epochs\n",
    "        self.loaded = False\n",
    "        self.X = X \n",
    "        self.XN = normalize_dataset(X)\n",
    "        self.y = y\n",
    "        self.optimizer = tf.keras.optimizers.Adam(lr)\n",
    "        self.mse = tf.keras.metrics.MeanSquaredError()\n",
    "        self.accuracy = tf.keras.metrics.MeanSquaredLogarithmicError()\n",
    "        self.precision = tf.keras.metrics.Precision()\n",
    "        self.loss_history = [e for e in range(epochs)]\n",
    "\n",
    "    @tf.function(reduce_retracing=True)\n",
    "    def accuracy_rrsse(self, predicted):\n",
    "        return tf.divide(tf.sqrt(\n",
    "            tf.divide(\n",
    "                tf.reduce_sum(tf.square(tf.abs((tf.subtract(predicted, self.y))))),\n",
    "                tf.reduce_sum(tf.square(tf.abs((tf.subtract(tf.reduce_mean(self.y), predicted)))))\n",
    "            )), predicted.shape[0]\n",
    "        )\n",
    "\n",
    "    @tf.function(reduce_retracing=True)\n",
    "    def loss(self, predicted):\n",
    "        return tf.losses.mean_squared_error(self.y, predicted)\n",
    "\n",
    "    @tf.function(reduce_retracing=True)\n",
    "    def calc_metrics(self):\n",
    "        self.acc_rrsse = self.accuracy_rrsse(self.predicted)\n",
    "        self.accuracy.update_state(self.y, self.predicted)\n",
    "        self.precision.update_state(self.y, self.predicted)\n",
    "        self.mse.update_state(self.y, self.predicted)\n",
    "\n",
    "    @tf.function(reduce_retracing=True)\n",
    "    def train_step(self, X):\n",
    "        for layer in self.layers:\n",
    "            X = layer(X)\n",
    "        return X\n",
    "\n",
    "    def train(self):\n",
    "        self.weights = model.train_step(self.XN)\n",
    "        self.vars = [self.layers[0].weights, self.layers[1].weights, self.layers[2].weights,self.layers[3].weights,self.layers[4].weights, self.layers[0].bias, self.layers[1].bias, self.layers[2].bias,self.layers[3].bias,self.layers[4].bias]\n",
    "\n",
    "        for e in range(self.epochs):\n",
    "            with tf.GradientTape(watch_accessed_variables=True, persistent=True) as tape:\n",
    "                self.weights = model.train_step(self.XN)\n",
    "                self.predicted = tf.reduce_sum(tf.subtract(tf.keras.layers.dot([self.XN, tf.transpose(self.weights)], axes=0), self.layers[len(self.layers)-1].bias))\n",
    "                loss = self.loss(self.predicted)\n",
    "                self.loss_history[e] = loss.numpy()\n",
    "                \n",
    "            grads = tape.gradient(loss, self.vars)\n",
    "            self.optimizer.apply_gradients(zip(grads, self.vars)) \n",
    "        print(self.predicted)\n",
    "\n",
    "model = MLPLinearRegressor([\n",
    "    Layer(neurons=10,),\n",
    "    Layer(neurons=10,),\n",
    "    Layer(neurons=10,),\n",
    "    Layer(neurons=10,),\n",
    "    Layer(neurons=X_train.shape[1], )\n",
    "],X_train, tf.squeeze(y_train), lr=0.001, epochs=100)\n",
    "\n",
    "\n",
    "model.train()\n",
    "model.calc_metrics()\n",
    "\n",
    "\n",
    "print(\"MeanSquaredError: \", model.mse.result().numpy())\n",
    "print(\"Keras Accuracy: \", model.accuracy.result().numpy())\n",
    "print(\"Keras Precision: \", model.precision.result().numpy())\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "ax[0].plot([e for e in range(model.epochs)], model.loss_history)\n",
    "\n",
    "ax[1].scatter(X_train[:, 0], y_train[:])\n",
    "ax[1].plot(X_train[:, 0], model.predicted[:])\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1cce27c8212bf6c5aa96f33a3d1153887721b66c5c8cb9adeaa83cce09196b75"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
