{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import sys\n",
    "import copy\n",
    "import logging\n",
    "import numpy as np\n",
    "#from stats import *\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "#from Layer import Layer\n",
    "import tensorflow as tf \n",
    "from pandas import DataFrame\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.datasets import fetch_california_housing, make_regression\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_stats(samples, features, loss, epochs, lr, batch_size, cross_k, r2, mse_train, mae_train, residual_train):\n",
    "    with open('../data/stats.csv', 'a') as f:\n",
    "        newrow = [samples, features, loss, epochs, lr, batch_size, cross_k, r2, mse_train, mae_train, residual_train]\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(newrow)\n",
    "\n",
    "def fill_dataset(dataframe: DataFrame):\n",
    "    for column in dataframe:\n",
    "        if dataframe[column].dtype != 'object':\n",
    "            dataframe[column] = dataframe[column].fillna(dataframe[column].mean())\n",
    "    return dataframe\n",
    "\n",
    "def normalize_dataset(X):\n",
    "    return tf.keras.utils.normalize(X)\n",
    "\n",
    "def remove_outliers(X, threshold=7):\n",
    "    z = np.abs(stats.zscore(X))\n",
    "    return X[(z<threshold).all(axis=1)][:, 0:-1], X[(z<threshold).all(axis=1)][: ,-1]\n",
    "\n",
    "def make_dataset(X_data,y_data,k):\n",
    "    X_data, y_data = remove_outliers(np.concatenate([X_data, y_data], axis=1))\n",
    "    def gen():\n",
    "        for train_index, test_index in KFold(k).split(X_data):\n",
    "            X_train, X_test = X_data[train_index], X_data[test_index]\n",
    "            XN_train, XN_test = normalize_dataset(X_data[train_index]), normalize_dataset(X_data[test_index])\n",
    "            y_train, y_test = y_data[train_index], y_data[test_index]\n",
    "            yield X_train,XN_train,y_train,X_test,XN_test,y_test\n",
    "\n",
    "    return tf.data.Dataset.from_generator(gen, (tf.double,tf.double,tf.double,tf.double,tf.double,tf.double))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_columns=[\"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\", \"H\", \"I\", \"J\", \"K\", \"L\", \"M\", \"N\", \"O\", \"P\", \"Q\", \"R\", \"S\", \"T\", \"U\", \"V\", \"W\", \"X\", \"Y\", \"Z\"]\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'  \n",
    "k = 2\n",
    "epochs = 800\n",
    "lr = 0.01\n",
    "batch_size = 200\n",
    "\n",
    "#X_train_b, X_test_b, y_train_b, y_test_b = train_test_split(housing.data, housing.target, test_size=0.98, random_state=2)\n",
    "XR, yR = make_regression(n_samples=1000, n_features=2, n_informative=5, noise=50, random_state=5)\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(XR, yR, test_size=0.20, random_state=2)\n",
    "columns = [\"{0}\".format(total_columns[i]) for i in range(XR.shape[1]+1)]\n",
    "dataframe = pd.DataFrame(np.concatenate([XR, np.reshape(yR, [-1, 1])], axis=1), columns=columns)\n",
    "#dataframe.drop([\"REGION\", \"PERIODTYPE\"], inplace=True, axis=1)\n",
    "dataframe.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1cce27c8212bf6c5aa96f33a3d1153887721b66c5c8cb9adeaa83cce09196b75"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
