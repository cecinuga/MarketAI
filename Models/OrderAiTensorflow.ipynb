{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import copy\n",
    "import logging\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.datasets import fetch_california_housing, make_regression\n",
    "sys.path.insert(0, 'C:\\\\Users\\\\Utente\\\\Desktop\\\\Dev\\\\Progetti\\\\OrderAi\\\\Models\\\\components\\\\')\n",
    "from Layer import Layer\n",
    "import AdamMB\n",
    "\n",
    "#housing = fetch_california_housing()\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'  \n",
    "k = 5\n",
    "epochs = 5000\n",
    "lr = 0.01\n",
    "batch_size = 500\n",
    "\n",
    "#X_train, X_test, y_train, y_test = train_test_split(housing.data, housing.target, test_size=0.98, random_state=2)\n",
    "XR, yR = make_regression(n_samples=10000, n_features=2, noise=50, random_state=5)\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(XR, yR, test_size=0.20, random_state=2)\n",
    "\n",
    "def normalize_dataset(X):\n",
    "    return tf.keras.utils.normalize(X)\n",
    "\n",
    "def make_dataset(X_data,y_data,k):\n",
    "    def gen():\n",
    "        for train_index, test_index in KFold(k).split(X_data):\n",
    "            X_train, X_test = X_data[train_index], X_data[test_index]\n",
    "            XN_train, XN_test = normalize_dataset(X_data[train_index]), normalize_dataset(X_data[test_index])\n",
    "            y_train, y_test = y_data[train_index], y_data[test_index]\n",
    "            yield X_train,XN_train,y_train,X_test,XN_test,y_test\n",
    "\n",
    "    return tf.data.Dataset.from_generator(gen, (tf.double,tf.double,tf.double,tf.double,tf.double,tf.double))\n",
    "    \n",
    "dataset = make_dataset(XR, yR, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "{{function_node __wrapped__Sub_device_/job:localhost/replica:0/task:0/device:CPU:0}} Incompatible shapes: [1000] vs. [2000] [Op:Sub]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[140], line 153\u001b[0m\n\u001b[0;32m    144\u001b[0m     \u001b[39m\"\"\"for data in dataset.as_numpy_iterator():\u001b[39;00m\n\u001b[0;32m    145\u001b[0m \u001b[39m        X_train, XN_train, y_train, X_test, XN_test, y_test = data\u001b[39;00m\n\u001b[0;32m    146\u001b[0m \u001b[39m        model.run(X_train, X_test, XN_train, XN_test, tf.squeeze(y_train), tf.squeeze(y_test), k)\u001b[39;00m\n\u001b[0;32m    147\u001b[0m \u001b[39m        k = k+1\u001b[39;00m\n\u001b[0;32m    148\u001b[0m \u001b[39m        break\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39m    return X_train, X_test, XN_train, XN_test, tf.squeeze(y_train), tf.squeeze(y_test)\"\"\"\u001b[39;00m\n\u001b[0;32m    150\u001b[0m     \u001b[39mreturn\u001b[39;00m X, X_t, XN, XN_t, tf\u001b[39m.\u001b[39msqueeze(y), tf\u001b[39m.\u001b[39msqueeze(y_t)\n\u001b[1;32m--> 153\u001b[0m X_train, X_test, XN_train, XN_test, y_train, y_test \u001b[39m=\u001b[39m run_model(dataset, model, X_train2, normalize_dataset(X_train2), X_test2, normalize_dataset(X_test2), y_train2, y_test2)\n",
      "Cell \u001b[1;32mIn[140], line 143\u001b[0m, in \u001b[0;36mrun_model\u001b[1;34m(data, model, X, XN, X_t, XN_t, y, y_t)\u001b[0m\n\u001b[0;32m    141\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrun_model\u001b[39m(data, model, X, XN, X_t, XN_t, y, y_t):\n\u001b[0;32m    142\u001b[0m     k \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m--> 143\u001b[0m     model\u001b[39m.\u001b[39;49mrun(X, X_t, XN, XN_t, tf\u001b[39m.\u001b[39;49msqueeze(y), tf\u001b[39m.\u001b[39;49msqueeze(y_t), \u001b[39m0\u001b[39;49m)\n\u001b[0;32m    144\u001b[0m     \u001b[39m\"\"\"for data in dataset.as_numpy_iterator():\u001b[39;00m\n\u001b[0;32m    145\u001b[0m \u001b[39m        X_train, XN_train, y_train, X_test, XN_test, y_test = data\u001b[39;00m\n\u001b[0;32m    146\u001b[0m \u001b[39m        model.run(X_train, X_test, XN_train, XN_test, tf.squeeze(y_train), tf.squeeze(y_test), k)\u001b[39;00m\n\u001b[0;32m    147\u001b[0m \u001b[39m        k = k+1\u001b[39;00m\n\u001b[0;32m    148\u001b[0m \u001b[39m        break\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39m    return X_train, X_test, XN_train, XN_test, tf.squeeze(y_train), tf.squeeze(y_test)\"\"\"\u001b[39;00m\n\u001b[0;32m    150\u001b[0m     \u001b[39mreturn\u001b[39;00m X, X_t, XN, XN_t, tf\u001b[39m.\u001b[39msqueeze(y), tf\u001b[39m.\u001b[39msqueeze(y_t)\n",
      "Cell \u001b[1;32mIn[140], line 129\u001b[0m, in \u001b[0;36mMLPLinearRegressor.run\u001b[1;34m(self, X, X_test, XN, XN_test, y, y_test, k)\u001b[0m\n\u001b[0;32m    127\u001b[0m grads \u001b[39m=\u001b[39m tape\u001b[39m.\u001b[39mgradient(loss, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvars)  \n\u001b[0;32m    128\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptimizer\u001b[39m.\u001b[39mapply_gradients(\u001b[39mzip\u001b[39m(grads, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvars))   \n\u001b[1;32m--> 129\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcalc_metrics(y, y_test, e, k, loss)\n",
      "Cell \u001b[1;32mIn[140], line 52\u001b[0m, in \u001b[0;36mMLPLinearRegressor.calc_metrics\u001b[1;34m(self, y, y_test, e, k, loss)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtest_mae\u001b[39m.\u001b[39mupdate_state(y_test, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpredicted_test)\n\u001b[0;32m     51\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtest_mse\u001b[39m.\u001b[39mupdate_state(y_test, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpredicted_test)\n\u001b[1;32m---> 52\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mupdate_states(loss, e\u001b[39m+\u001b[39;49m(k\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mepochs), y)\n",
      "Cell \u001b[1;32mIn[140], line 42\u001b[0m, in \u001b[0;36mMLPLinearRegressor.update_states\u001b[1;34m(self, loss, i, y)\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmse_test_error_history[i] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtest_mse\u001b[39m.\u001b[39mresult()\u001b[39m.\u001b[39mnumpy()\n\u001b[0;32m     41\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mr2_accuracy_tr[i] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mr2(y, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpredicted_train)\n\u001b[1;32m---> 42\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mr2_accuracy_tt[i] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mr2(y_test, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpredicted_test)\n\u001b[0;32m     43\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresidual_tr[i] \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mreduce_mean(tf\u001b[39m.\u001b[39msubtract(y, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpredicted_train))\n\u001b[0;32m     44\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresidual_tt[i] \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mreduce_mean(tf\u001b[39m.\u001b[39msubtract(y_test, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpredicted_test))\n",
      "Cell \u001b[1;32mIn[140], line 62\u001b[0m, in \u001b[0;36mMLPLinearRegressor.r2\u001b[1;34m(self, y, y_pred)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mr2\u001b[39m(\u001b[39mself\u001b[39m, y, y_pred):\n\u001b[0;32m     59\u001b[0m     \u001b[39mreturn\u001b[39;00m tf\u001b[39m.\u001b[39msubtract(\n\u001b[0;32m     60\u001b[0m         tf\u001b[39m.\u001b[39mconvert_to_tensor(\u001b[39m1\u001b[39m, dtype\u001b[39m=\u001b[39mtf\u001b[39m.\u001b[39mfloat64), \n\u001b[0;32m     61\u001b[0m         tf\u001b[39m.\u001b[39mdivide(\n\u001b[1;32m---> 62\u001b[0m             tf\u001b[39m.\u001b[39mreduce_sum(tf\u001b[39m.\u001b[39msquare(tf\u001b[39m.\u001b[39;49msubtract(y, y_pred))),\n\u001b[0;32m     63\u001b[0m             tf\u001b[39m.\u001b[39mreduce_sum(tf\u001b[39m.\u001b[39msquare(tf\u001b[39m.\u001b[39msubtract(y, tf\u001b[39m.\u001b[39mreduce_mean(y_pred))))\n\u001b[0;32m     64\u001b[0m         )\n\u001b[0;32m     65\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m--> 153\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m    154\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    155\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\framework\\ops.py:7215\u001b[0m, in \u001b[0;36mraise_from_not_ok_status\u001b[1;34m(e, name)\u001b[0m\n\u001b[0;32m   7213\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mraise_from_not_ok_status\u001b[39m(e, name):\n\u001b[0;32m   7214\u001b[0m   e\u001b[39m.\u001b[39mmessage \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (\u001b[39m\"\u001b[39m\u001b[39m name: \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m name \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m-> 7215\u001b[0m   \u001b[39mraise\u001b[39;00m core\u001b[39m.\u001b[39m_status_to_exception(e) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: {{function_node __wrapped__Sub_device_/job:localhost/replica:0/task:0/device:CPU:0}} Incompatible shapes: [1000] vs. [2000] [Op:Sub]"
     ]
    }
   ],
   "source": [
    "class MLPLinearRegressor(tf.Module):\n",
    "    def __init__(self, layers, k, epochs=100, lr=0.01, batch_size=50):\n",
    "        self.layers = layers\n",
    "        self.epochs = epochs\n",
    "        self.batch_size = batch_size\n",
    "        self.batch_counter = 0\n",
    "        self.learning_rate = tf.keras.optimizers.schedules.ExponentialDecay(lr, decay_steps=1000000, decay_rate=0.96, staircase=True)\n",
    "        self.optimizer = tf.keras.optimizers.Adam(self.learning_rate)\n",
    "        self.train_mse = tf.keras.metrics.MeanSquaredError()\n",
    "        self.train_mae = tf.keras.metrics.MeanAbsoluteError()\n",
    "        self.train_accuracy = tf.keras.metrics.MeanSquaredLogarithmicError()\n",
    "        self.test_mse = tf.keras.metrics.MeanSquaredError()\n",
    "        self.test_mae = tf.keras.metrics.MeanAbsoluteError()\n",
    "        self.test_accuracy = tf.keras.metrics.MeanSquaredLogarithmicError()\n",
    "        self.regularizer = tf.keras.layers.ActivityRegularization()\n",
    "        self.loss_history = [e for e in range(epochs*k)]\n",
    "        self.bias_history = [e for e in range(epochs*k)]\n",
    "        self.mae_train_error_history = [e for e in range(epochs*k)]\n",
    "        self.mse_train_error_history = [e for e in range(epochs*k)]\n",
    "        self.mae_test_error_history = [e for e in range(epochs*k)]\n",
    "        self.mse_test_error_history = [e for e in range(epochs*k)]\n",
    "        self.residual_tr = [e for e in range(epochs*k)]\n",
    "        self.residual_tt = [e for e in range(epochs*k)]\n",
    "        self.r2_accuracy_tr = [e for e in range(epochs*k)]\n",
    "        self.r2_accuracy_tt = [e for e in range(epochs*k)]\n",
    "        self.loaded = False\n",
    "\n",
    "    def reset_history_metrics(self):\n",
    "        self.train_mse.reset_state()\n",
    "        self.train_mae.reset_state()\n",
    "        self.test_mse.reset_state()\n",
    "        self.test_mae.reset_state()\n",
    "    \n",
    "    def update_states(self, loss, i, y):\n",
    "        self.bias_history[i] = self.bias\n",
    "        self.loss_history[i] = loss.numpy()\n",
    "        self.mae_train_error_history[i] = self.train_mae.result().numpy()\n",
    "        self.mse_train_error_history[i] = self.train_mse.result().numpy()\n",
    "        self.mae_test_error_history[i] = self.test_mae.result().numpy()\n",
    "        self.mse_test_error_history[i] = self.test_mse.result().numpy()\n",
    "        self.r2_accuracy_tr[i] = self.r2(y, self.predicted_train)\n",
    "        self.r2_accuracy_tt[i] = self.r2(y_test, self.predicted_test)\n",
    "        self.residual_tr[i] = tf.reduce_mean(tf.subtract(y, self.predicted_train))\n",
    "        self.residual_tt[i] = tf.reduce_mean(tf.subtract(y_test, self.predicted_test))\n",
    "\n",
    "    def calc_metrics(self, y, y_test, e, k, loss):\n",
    "        self.reset_history_metrics()\n",
    "        self.train_mae.update_state(y, self.predicted_train)\n",
    "        self.train_mse.update_state(y, self.predicted_train)\n",
    "        self.test_mae.update_state(y_test, self.predicted_test)\n",
    "        self.test_mse.update_state(y_test, self.predicted_test)\n",
    "        self.update_states(loss, e+(k*self.epochs), y)\n",
    "\n",
    "    def verify_batch(self, X, X_test):\n",
    "        if self.batch_counter == X:\n",
    "            self.batch_counter = 0\n",
    "        \n",
    "    def r2(self, y, y_pred):\n",
    "        print(y.shape, y_pred.shape)\n",
    "        return tf.subtract(\n",
    "            tf.convert_to_tensor(1, dtype=tf.float64), \n",
    "            tf.divide(\n",
    "                tf.reduce_sum(tf.square(tf.subtract(y, y_pred))),\n",
    "                tf.reduce_sum(tf.square(tf.subtract(y, tf.reduce_mean(y_pred))))\n",
    "            )\n",
    "        )\n",
    "\n",
    "    @tf.function\n",
    "    def lasso(self):\n",
    "        lassos = [w for w in range(len(self.layers))]\n",
    "        for w in range(len(self.layers)):\n",
    "            lassos[w] = tf.reduce_sum(tf.norm(self.layers[w].weights))\n",
    "        return tf.reduce_mean(lassos)\n",
    "\n",
    "    @tf.function\n",
    "    def ridge(self):\n",
    "        ridges = [w for w in range(len(self.layers))]\n",
    "        for w in range(len(self.layers)):\n",
    "            ridges[w] = tf.reduce_sum(tf.square(tf.norm(self.layers[w].weights)))\n",
    "        return tf.reduce_mean(ridges)\n",
    "\n",
    "    @tf.function(reduce_retracing=True)\n",
    "    def loss(self, y, predicted):\n",
    "        return tf.add(tf.add(tf.losses.MSE(y, predicted), self.lasso()), self.ridge())\n",
    "        \n",
    "    @tf.function(reduce_retracing=True)\n",
    "    def _predict_train(self, X, weights):\n",
    "        compressed_weights = tf.reduce_mean(tf.subtract(tf.multiply(X, weights), self.bias), axis=1)\n",
    "        return tf.reduce_mean(tf.add(tf.multiply(tf.transpose(X), compressed_weights), self.bias), axis=1, name=\"Predict_Train\")\n",
    "\n",
    "    @tf.function\n",
    "    def _predict(self, X_test, compressed_weights):\n",
    "        return tf.reduce_mean(tf.add(tf.multiply(X_test, compressed_weights), self.bias), axis=1, name=\"Predict_Test\")\n",
    "    \n",
    "    def predict(self, x):\n",
    "        return tf.reduce_mean(tf.add(tf.multiply(x, self.compressed_weights), self.bias))\n",
    "\n",
    "    @tf.function(reduce_retracing=True)\n",
    "    def _forward(self, X):\n",
    "        for layer in self.layers:\n",
    "            X = layer(X)\n",
    "        return X\n",
    "\n",
    "    @tf.function(reduce_retracing=True)\n",
    "    def _backprop(self, X, XN, X_test, y):\n",
    "        batch_xn = XN[self.batch_counter:self.batch_counter+self.batch_size, :]\n",
    "        weights = self._forward(batch_xn)\n",
    "        self.bias = self.layers[len(self.layers)-1].bias\n",
    "\n",
    "        compressed_weights = tf.reduce_mean(tf.add(tf.multiply(tf.transpose(batch_xn), tf.reduce_mean(weights, axis=0)), self.bias), axis=1)\n",
    "\n",
    "        predicted_train = self._predict(X, compressed_weights)\n",
    "        predicted_test = self._predict(X_test, compressed_weights)\n",
    "\n",
    "        loss = tf.nn.scale_regularization_loss(self.loss(y, predicted_train))\n",
    "\n",
    "        self.vars = [self.layers[0].weights, self.layers[1].weights, self.layers[2].weights,self.layers[3].weights,self.layers[4].weights, self.layers[0].bias, self.layers[1].bias, self.layers[2].bias,self.layers[3].bias,self.layers[4].bias]\n",
    "        self.batch_counter = self.batch_counter + self.batch_size\n",
    "        return loss, compressed_weights, predicted_train, predicted_test\n",
    "\n",
    "    def run(self, X, X_test, XN, XN_test, y, y_test, k):\n",
    "        for e in range(self.epochs):\n",
    "            self.verify_batch(X.shape[0], X_test.shape[0])\n",
    "            \n",
    "            with tf.GradientTape(watch_accessed_variables=True, persistent=True) as tape:\n",
    "                loss, self.compressed_weights, self.predicted_train, self.predicted_test = self._backprop(X, XN, X_test, y)\n",
    "            \n",
    "            grads = tape.gradient(loss, self.vars)  \n",
    "            self.optimizer.apply_gradients(zip(grads, self.vars))   \n",
    "            self.calc_metrics(y, y_test, e, k, loss)\n",
    "\n",
    "kk = 1\n",
    "model = MLPLinearRegressor([\n",
    "    Layer(activation=tf.nn.relu),\n",
    "    Layer(activation=tf.nn.relu),\n",
    "    Layer(activation=tf.nn.relu),\n",
    "    Layer(activation=tf.sigmoid),\n",
    "    Layer()\n",
    "], kk, epochs=epochs, lr=lr, batch_size=batch_size)\n",
    "\n",
    "\n",
    "def run_model(data, model, X, XN, X_t, XN_t, y, y_t):\n",
    "    k = 0\n",
    "    #model.run(X, X_t, XN, XN_t, tf.squeeze(y), tf.squeeze(y_t))\n",
    "    for data in dataset.as_numpy_iterator():\n",
    "        X_train, XN_train, y_train, X_test, XN_test, y_test = data\n",
    "        model.run(X_train, X_test, XN_train, XN_test, tf.squeeze(y_train), tf.squeeze(y_test), k)\n",
    "        k = k+1\n",
    "        break\n",
    "    return X_train, X_test, XN_train, XN_test, tf.squeeze(y_train), tf.squeeze(y_test)\n",
    "     \n",
    "     \n",
    "X_train, X_test, XN_train, XN_test, y_train, y_test = run_model(dataset, model, X_train2, normalize_dataset(X_train2), X_test2, normalize_dataset(X_test2), y_train2, y_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Original:  139.96402002732958 \n",
      "Predicted:  0.012062545296775671 \n",
      "Tested: 0.0004156449969432318 \n",
      "\n",
      "Train_MeanSquaredError:  9500.132\n",
      "Train_MeanAbsoluteError:  77.683044\n",
      "Train_MeanSquaredLogError:  0.0\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'int' object has no attribute 'numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[136], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mTrain_MeanAbsoluteError: \u001b[39m\u001b[39m\"\u001b[39m, model\u001b[39m.\u001b[39mtrain_mae\u001b[39m.\u001b[39mresult()\u001b[39m.\u001b[39mnumpy())\n\u001b[0;32m      4\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mTrain_MeanSquaredLogError: \u001b[39m\u001b[39m\"\u001b[39m, model\u001b[39m.\u001b[39mtrain_accuracy\u001b[39m.\u001b[39mresult()\u001b[39m.\u001b[39mnumpy())\n\u001b[1;32m----> 5\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mTrain_R2Accuracy: \u001b[39m\u001b[39m\"\u001b[39m, model\u001b[39m.\u001b[39;49mr2_accuracy_tr[(epochs\u001b[39m*\u001b[39;49mkk)\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m]\u001b[39m.\u001b[39;49mnumpy()) \n\u001b[0;32m      6\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39m--------------------------------------------------------\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      7\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mTest_MeanSquaredError: \u001b[39m\u001b[39m\"\u001b[39m, model\u001b[39m.\u001b[39mtest_mse\u001b[39m.\u001b[39mresult()\u001b[39m.\u001b[39mnumpy())\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'int' object has no attribute 'numpy'"
     ]
    }
   ],
   "source": [
    "print(\"\\nOriginal: \", y_test[0].numpy(), \"\\nPredicted: \", model.predict(X_test[0]).numpy(), \"\\nTested:\", model.predicted_test[0].numpy(), \"\\n\")\n",
    "print(\"Train_MeanSquaredError: \", model.train_mse.result().numpy())\n",
    "print(\"Train_MeanAbsoluteError: \", model.train_mae.result().numpy())\n",
    "print(\"Train_MeanSquaredLogError: \", model.train_accuracy.result().numpy())\n",
    "print(\"Train_R2Accuracy: \", model.r2_accuracy_tr[(epochs*kk)-1].numpy()) \n",
    "print('--------------------------------------------------------')\n",
    "print(\"Test_MeanSquaredError: \", model.test_mse.result().numpy())\n",
    "print(\"Train_MeanAbsoluteError: \", model.test_mae.result().numpy())\n",
    "print(\"Test_MeanSquaredLogError: \", model.test_accuracy.result().numpy())\n",
    "print(\"Train_R2Accuracy: \", model.r2_accuracy_tt[(epochs*kk)-1].numpy()) \n",
    "\n",
    "fig, ax = plt.subplots(2, 5, figsize=(20, 10))\n",
    "ax[0, 0].plot([e for e in range(epochs*kk)], model.loss_history, label=\"Loss\")\n",
    "ax[0, 0].set_ylabel('Loss & Bias History')\n",
    "ax[0, 0].set_xlabel('Epochs')\n",
    "ax[0, 0].legend()\n",
    "\n",
    "ax[0, 1].plot([e for e in range(epochs*kk)], model.mse_train_error_history, label=\"Train MSE\")\n",
    "ax[0, 1].plot([e for e in range(epochs*kk)], model.mse_test_error_history, label=\"Test MSE\")\n",
    "ax[0, 1].set_ylabel('Metrics History')\n",
    "ax[0, 1].set_xlabel('Epochs')\n",
    "ax[0, 1].legend()\n",
    "\n",
    "ax[1, 0].plot([e for e in range(epochs*kk)], model.bias_history, label=\"Bias\")\n",
    "ax[1, 0].plot([e for e in range(epochs*kk)], model.residual_tr, label=\"Train Residual\")\n",
    "ax[1, 0].plot([e for e in range(epochs*kk)], model.residual_tt, label=\"Test Residual\")\n",
    "ax[1, 0].set_xlabel('Residuals')\n",
    "ax[1, 0].set_ylabel('Epochs')\n",
    "ax[1, 0].legend()\n",
    "\n",
    "ax[1, 1].plot([e for e in range(epochs*kk)], model.r2_accuracy_tr, label=\"Train R2 Accuracy\")\n",
    "ax[1, 1].plot([e for e in range(epochs*kk)], model.r2_accuracy_tt, label=\"Test R2 Accuracy\")\n",
    "ax[1, 1].set_xlabel('R2 Accuracy')\n",
    "ax[1, 1].set_ylabel('Epochs')\n",
    "ax[1, 1].legend()\n",
    "\n",
    "ax[0, 2].plot([e for e in range(epochs*kk)], model.mae_test_error_history, label=\"Test MAE\")\n",
    "ax[0, 2].plot([e for e in range(epochs*kk)], model.mae_train_error_history, label=\"Train MAE\")\n",
    "ax[0, 2].legend()\n",
    "\n",
    "ax[0, 3].scatter(X_train[:, -1], y_train[:])\n",
    "ax[0, 3].plot(X_train[:, -1], model.predicted_train[:], color='r')\n",
    "#ax[0, 3].set_ylim([-300, 300])\n",
    "#ax[0, 3].set_xlim(-3,3)\n",
    "ax[0, 3].set_xlabel(\"Train\")\n",
    "\n",
    "ax[0, 4].scatter(X_test[:, -1], y_test[:])\n",
    "ax[0, 4].plot(X_test[:, -1], model.predicted_test[:], color='r')\n",
    "#ax[0, 4].set_ylim([-200, 200])\n",
    "#ax[0, 4].set_xlim(-3,3)\n",
    "ax[0, 4].set_xlabel(\"Test\")\n",
    "\n",
    "\"\"\"\n",
    "fig3d = plt.figure()\n",
    "ax3d = fig3d.add_subplot(projection='3d')\n",
    "ax3d.scatter(X_train[:, 0], X_train[:, 1], y_train[:])\n",
    "ax3d.plot(X_train[:, 0], X_train[:, 1], model.predicted_train[:], color='r')\"\"\"\n",
    "\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1cce27c8212bf6c5aa96f33a3d1153887721b66c5c8cb9adeaa83cce09196b75"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
