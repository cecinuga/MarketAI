{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import sys\n",
    "import copy\n",
    "import time\n",
    "import logging\n",
    "import datetime\n",
    "import numpy as np\n",
    "#from stats import *\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "#from Layer import Layer\n",
    "import tensorflow as tf \n",
    "from pandas import DataFrame\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.datasets import fetch_california_housing, make_regression\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_stats(samples, features, loss, epochs, lr, batch_size, cross_k, r2, mse_train, mae_train, residual_train):\n",
    "    with open('../data/stats.csv', 'a') as f:\n",
    "        newrow = [samples, features, loss, epochs, lr, batch_size, cross_k, r2, mse_train, mae_train, residual_train]\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(newrow)\n",
    "\n",
    "def fill_dataset(dataframe: DataFrame):\n",
    "    for column in dataframe:\n",
    "        if dataframe[column].dtype != 'object':\n",
    "            dataframe[column] = dataframe[column].fillna(dataframe[column].mean())\n",
    "    return dataframe\n",
    "\n",
    "def normalize_dataset(X):\n",
    "    return tf.keras.utils.normalize(X)\n",
    "\n",
    "def remove_outliers(X, threshold=7):\n",
    "    z = np.abs(stats.zscore(X))\n",
    "    return X[(z<threshold).all(axis=1)][:, 0:-1], X[(z<threshold).all(axis=1)][: ,-1]\n",
    "\n",
    "def make_dataset(X_data,y_data,k):\n",
    "    X_data, y_data = remove_outliers(np.concatenate([X_data, y_data], axis=1))\n",
    "    def gen():\n",
    "        for train_index, test_index in KFold(k).split(X_data):\n",
    "            X_train, X_test = X_data[train_index], X_data[test_index]\n",
    "            XN_train, XN_test = normalize_dataset(X_data[train_index]), normalize_dataset(X_data[test_index])\n",
    "            y_train, y_test = y_data[train_index], y_data[test_index]\n",
    "            yield X_train,XN_train,y_train,X_test,XN_test,y_test\n",
    "\n",
    "    return tf.data.Dataset.from_generator(gen, (tf.double,tf.double,tf.double,tf.double,tf.double,tf.double))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1259</th>\n",
       "      <td>67.7142</td>\n",
       "      <td>68.4014</td>\n",
       "      <td>66.8928</td>\n",
       "      <td>67.8542</td>\n",
       "      <td>158168416.0</td>\n",
       "      <td>-0.1400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1260</th>\n",
       "      <td>68.0714</td>\n",
       "      <td>69.2771</td>\n",
       "      <td>67.6071</td>\n",
       "      <td>68.5614</td>\n",
       "      <td>129029425.0</td>\n",
       "      <td>-0.4900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1261</th>\n",
       "      <td>68.5014</td>\n",
       "      <td>68.9114</td>\n",
       "      <td>66.8205</td>\n",
       "      <td>66.8428</td>\n",
       "      <td>151829363.0</td>\n",
       "      <td>1.6586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1262</th>\n",
       "      <td>66.7442</td>\n",
       "      <td>67.6628</td>\n",
       "      <td>66.1742</td>\n",
       "      <td>66.7156</td>\n",
       "      <td>118721995.0</td>\n",
       "      <td>0.0286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1263</th>\n",
       "      <td>66.3599</td>\n",
       "      <td>67.3771</td>\n",
       "      <td>66.2885</td>\n",
       "      <td>66.6556</td>\n",
       "      <td>88809154.0</td>\n",
       "      <td>-0.2957</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         open     high      low    close       volume  target\n",
       "1259  67.7142  68.4014  66.8928  67.8542  158168416.0 -0.1400\n",
       "1260  68.0714  69.2771  67.6071  68.5614  129029425.0 -0.4900\n",
       "1261  68.5014  68.9114  66.8205  66.8428  151829363.0  1.6586\n",
       "1262  66.7442  67.6628  66.1742  66.7156  118721995.0  0.0286\n",
       "1263  66.3599  67.3771  66.2885  66.6556   88809154.0 -0.2957"
      ]
     },
     "execution_count": 479,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_columns=[\"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\", \"H\", \"I\", \"J\", \"K\", \"L\", \"M\", \"N\", \"O\", \"P\", \"Q\", \"R\", \"S\", \"T\", \"U\", \"V\", \"W\", \"X\", \"Y\", \"Z\"]\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'  \n",
    "k = 2\n",
    "batch_size = 120\n",
    "\n",
    "#XR, yR = make_regression(n_samples=1000, n_features=2, n_informative=5, noise=50, random_state=5)\n",
    "#X_train, X_test, y_train, y_test = train_test_split(XR, yR, test_size=0.20, random_state=2)\n",
    "#columns = [\"{0}\".format(total_columns[i]) for i in range(XR.shape[1]+1)]\n",
    "#dataframe = pd.DataFrame(np.concatenate([XR, np.reshape(yR, [-1, 1])], axis=1), columns=columns)\n",
    "\n",
    "stocks = pd.read_csv(\"../data/datasets/all_stocks_5yr.csv\")\n",
    "stocks = pd.DataFrame(stocks)\n",
    "filter = stocks[\"Name\"]==\"AAPL\"\n",
    "stocks = stocks.where(filter).dropna()\n",
    "stocks.drop(['Name', \"date\"], axis=1, inplace=True)\n",
    "stocks['target'] = stocks['open'].fillna(stocks['open'].mean())-stocks['close'].fillna(stocks['close'].mean())\n",
    "#data['type'] = 1 if dataframe['open']-dataframe['close']>=0 else 0\n",
    "rnnstocks = stocks.values[0:100, :]\n",
    "n_features = len(rnnstocks[0])\n",
    "n_rows = 10\n",
    "n_ciclics = 10\n",
    "data = np.array(rnnstocks).reshape(n_ciclics, n_rows, n_features)\n",
    "X = data[:, 0:-1, :]\n",
    "Y = data[:, -1, :]\n",
    "\n",
    "stocks.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  features           VIF\n",
      "0     open           inf\n",
      "1     high  5.060050e+04\n",
      "2      low  4.511802e+04\n",
      "3    close           inf\n",
      "4   volume  2.630125e+00\n",
      "5   target           inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Utente\\AppData\\Roaming\\Python\\Python39\\site-packages\\statsmodels\\stats\\outliers_influence.py:195: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  vif = 1. / (1. - r_squared_i)\n"
     ]
    }
   ],
   "source": [
    "vif_data = pd.DataFrame()\n",
    "vif_data[\"features\"] = stocks.columns\n",
    "vif_data[\"VIF\"] = [variance_inflation_factor(stocks.values, i) for i in range(len(stocks.columns))]\n",
    "print(vif_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNLayer(tf.Module):\n",
    "    def __init__(self, units, input_dim, output_dim):\n",
    "        #Initialize weights matrices\n",
    "        self.W_xh = tf.Variable(tf.random.uniform(shape=(units, input_dim)), trainable=True)\n",
    "        self.W_hh = tf.Variable(tf.random.uniform(shape=(units, units)), trainable=True)\n",
    "        self.W_hy = tf.Variable(tf.random.uniform(shape=(output_dim, units)), trainable=True)\n",
    "        self.bias = tf.Variable(tf.ones(units), trainable=True)\n",
    "        #Initialize hidden state (Memory)\n",
    "        self.h = tf.zeros([units, 1])\n",
    "    \n",
    "    @tf.function(reduce_retracing=True)\n",
    "    def __call__(self, x):\n",
    "        print(\"[#] W_xh: {0}, W_hh: {1}, W_hy: {2}, W_bias: {3}\".format(self.W_xh.shape, self.W_hh.shape, self.W_hy.shape, self.bias.shape))\n",
    "        updated_input = tf.multiply(self.W_xh, x)\n",
    "        updated_memory = tf.multiply(self.W_hh, self.h)\n",
    "        print(\"[#] updated_input: {0}, updated_memory: {1}\".format(updated_input.shape, updated_memory.shape))\n",
    "        self.h = tf.nn.tanh(\n",
    "            tf.add(tf.transpose(\n",
    "                tf.matmul(updated_memory, updated_input)), \n",
    "                self.bias\n",
    "            )\n",
    "        )\n",
    "        output = tf.multiply(self.W_hy, self.h)\n",
    "        print(\"[#] h: {0}, output: {1}\".format(self.h.shape, output.shape))\n",
    "        return output, self.h        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MarketAI(tf.Module):\n",
    "    def __init__(self, layers, epochs=100, lr=0.01):\n",
    "        self.epochs = epochs\n",
    "        self.layers = layers\n",
    "        self.Adam = tf.optimizers.Adam(lr)\n",
    "        self.loss_history = [e for e in range(self.epochs)]\n",
    "\n",
    "    @tf.function(reduce_retracing=True)\n",
    "    def loss(self, y, predicted):\n",
    "        return tf.losses.MSE(y, predicted)\n",
    "    \n",
    "    def history(self, e):\n",
    "        self.loss_history[e] = self.loss\n",
    "\n",
    "    def train(self, X):\n",
    "        print(\"[#] X: {0}, Y: {1}\".format(X.shape, Y.shape))\n",
    "        X = tf.convert_to_tensor(X, dtype=tf.float32)\n",
    "        self.vars = [self.layers[0].W_xh, self.layers[0].W_hh, self.layers[0].W_hy, self.layers[0].bias]\n",
    "        for e in range(self.epochs):\n",
    "            for layer in self.layers:\n",
    "                with tf.GradientTape(watch_accessed_variables=True, persistent=True) as tape:\n",
    "                    output, h = layer(X)\n",
    "            losses = self.loss(X, tf.transpose(output))\n",
    "            self.loss = tf.reduce_sum(losses)\n",
    "            print(\"[#] Loss: {0}\".format(self.loss))\n",
    "\n",
    "            grads = tape.gradient(self.loss, self.vars)  \n",
    "            self.Adam.apply_gradients(zip(grads, self.vars))\n",
    "            self.history(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[#] X: (9, 6), Y: (6,)\n",
      "[#] W_xh: (9, 6), W_hh: (9, 9), W_hy: (6, 9), W_bias: (9,)\n",
      "[#] updated_input: (9, 6), updated_memory: (9, 9)\n",
      "[#] h: (6, 9), output: (6, 9)\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function RNNLayer.__call__ at 0x0000023110EA64C0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "[#] Loss: 2.245457005982515e+16\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "No gradients provided for any variable: (['Variable:0', 'Variable:0', 'Variable:0', 'Variable:0'],). Provided `grads_and_vars` is ((None, <tf.Variable 'Variable:0' shape=(9, 6) dtype=float32, numpy=\narray([[0.88725734, 0.5995213 , 0.1933645 , 0.5238522 , 0.06317687,\n        0.3710934 ],\n       [0.36416936, 0.00256801, 0.9992962 , 0.70852065, 0.8219024 ,\n        0.7320446 ],\n       [0.34955585, 0.76306975, 0.4321556 , 0.8407053 , 0.00300968,\n        0.60346115],\n       [0.559649  , 0.26802206, 0.8240807 , 0.66092885, 0.00311875,\n        0.7176231 ],\n       [0.07046938, 0.31595325, 0.609781  , 0.40504277, 0.4049238 ,\n        0.60967994],\n       [0.20363533, 0.4713906 , 0.6631266 , 0.5226294 , 0.9403013 ,\n        0.24795556],\n       [0.55395293, 0.8198019 , 0.56277215, 0.11933553, 0.12034929,\n        0.5626768 ],\n       [0.80094254, 0.14054179, 0.38852906, 0.11670983, 0.19844139,\n        0.15899241],\n       [0.337551  , 0.5983615 , 0.63147414, 0.7051363 , 0.9954115 ,\n        0.7256198 ]], dtype=float32)>), (None, <tf.Variable 'Variable:0' shape=(9, 9) dtype=float32, numpy=\narray([[0.3307606 , 0.00945663, 0.20713925, 0.33151186, 0.09123445,\n        0.19223225, 0.7020471 , 0.9399637 , 0.19870114],\n       [0.9222454 , 0.5660691 , 0.2424972 , 0.67506707, 0.30953145,\n        0.6818143 , 0.8776636 , 0.03674424, 0.05496967],\n       [0.17781079, 0.5663899 , 0.8069583 , 0.22616959, 0.06723011,\n        0.6656265 , 0.15640712, 0.6028372 , 0.06410778],\n       [0.8404925 , 0.41855812, 0.07419991, 0.3798039 , 0.1709181 ,\n        0.13665378, 0.46457303, 0.04188311, 0.8394971 ],\n       [0.08059514, 0.9196471 , 0.8023145 , 0.2743758 , 0.4729755 ,\n        0.60347533, 0.70600677, 0.483505  , 0.26264012],\n       [0.61654353, 0.5198692 , 0.17046595, 0.05148172, 0.20338058,\n        0.8321955 , 0.53042686, 0.896618  , 0.58778095],\n       [0.54212296, 0.26471233, 0.6563455 , 0.81151223, 0.87764883,\n        0.37578297, 0.6802931 , 0.735088  , 0.5409715 ],\n       [0.8927363 , 0.74577737, 0.40862393, 0.9608593 , 0.5893332 ,\n        0.34054184, 0.07919669, 0.933022  , 0.60402036],\n       [0.47236383, 0.43862855, 0.77626085, 0.24009776, 0.00291228,\n        0.5353006 , 0.97053874, 0.59289396, 0.8790935 ]], dtype=float32)>), (None, <tf.Variable 'Variable:0' shape=(6, 9) dtype=float32, numpy=\narray([[0.70982015, 0.27539325, 0.6011385 , 0.07611561, 0.9435061 ,\n        0.5364251 , 0.72496164, 0.38103282, 0.58070695],\n       [0.96982956, 0.03967583, 0.5653516 , 0.17442071, 0.7998333 ,\n        0.2827803 , 0.5764619 , 0.33283865, 0.6365974 ],\n       [0.01781499, 0.68678486, 0.5397886 , 0.9713186 , 0.04312575,\n        0.20271134, 0.1596967 , 0.4220227 , 0.4085616 ],\n       [0.52900815, 0.821771  , 0.9354985 , 0.7797735 , 0.09302151,\n        0.9428786 , 0.8968643 , 0.57245517, 0.51524746],\n       [0.01930261, 0.47409034, 0.24466646, 0.19588721, 0.68170893,\n        0.08301294, 0.07731783, 0.05730796, 0.7885418 ],\n       [0.7355459 , 0.8096719 , 0.18366814, 0.38870835, 0.09822619,\n        0.7393323 , 0.6929877 , 0.24453783, 0.74897826]], dtype=float32)>), (None, <tf.Variable 'Variable:0' shape=(9,) dtype=float32, numpy=array([1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>)).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_7416\\47116015.py\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mRNNLayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_rows\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_features\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m ], epochs, lr)\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_7416\\2950166052.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, X, Y)\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m             \u001b[0mgrads\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvars\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvars\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Utente\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py\u001b[0m in \u001b[0;36mapply_gradients\u001b[1;34m(self, grads_and_vars, name, experimental_aggregate_gradients)\u001b[0m\n\u001b[0;32m    687\u001b[0m           \u001b[0mRuntimeError\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mIf\u001b[0m \u001b[0mcalled\u001b[0m \u001b[1;32min\u001b[0m \u001b[0ma\u001b[0m \u001b[0mcross\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mreplica\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    688\u001b[0m         \"\"\"\n\u001b[1;32m--> 689\u001b[1;33m         \u001b[0mgrads_and_vars\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptimizer_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilter_empty_gradients\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrads_and_vars\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    690\u001b[0m         \u001b[0mvar_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mv\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mgrads_and_vars\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    691\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Utente\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\utils.py\u001b[0m in \u001b[0;36mfilter_empty_gradients\u001b[1;34m(grads_and_vars)\u001b[0m\n\u001b[0;32m     75\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mfiltered\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m         \u001b[0mvariable\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mgrads_and_vars\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 77\u001b[1;33m         raise ValueError(\n\u001b[0m\u001b[0;32m     78\u001b[0m             \u001b[1;34mf\"No gradients provided for any variable: {variable}. \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m             \u001b[1;34mf\"Provided `grads_and_vars` is {grads_and_vars}.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: No gradients provided for any variable: (['Variable:0', 'Variable:0', 'Variable:0', 'Variable:0'],). Provided `grads_and_vars` is ((None, <tf.Variable 'Variable:0' shape=(9, 6) dtype=float32, numpy=\narray([[0.88725734, 0.5995213 , 0.1933645 , 0.5238522 , 0.06317687,\n        0.3710934 ],\n       [0.36416936, 0.00256801, 0.9992962 , 0.70852065, 0.8219024 ,\n        0.7320446 ],\n       [0.34955585, 0.76306975, 0.4321556 , 0.8407053 , 0.00300968,\n        0.60346115],\n       [0.559649  , 0.26802206, 0.8240807 , 0.66092885, 0.00311875,\n        0.7176231 ],\n       [0.07046938, 0.31595325, 0.609781  , 0.40504277, 0.4049238 ,\n        0.60967994],\n       [0.20363533, 0.4713906 , 0.6631266 , 0.5226294 , 0.9403013 ,\n        0.24795556],\n       [0.55395293, 0.8198019 , 0.56277215, 0.11933553, 0.12034929,\n        0.5626768 ],\n       [0.80094254, 0.14054179, 0.38852906, 0.11670983, 0.19844139,\n        0.15899241],\n       [0.337551  , 0.5983615 , 0.63147414, 0.7051363 , 0.9954115 ,\n        0.7256198 ]], dtype=float32)>), (None, <tf.Variable 'Variable:0' shape=(9, 9) dtype=float32, numpy=\narray([[0.3307606 , 0.00945663, 0.20713925, 0.33151186, 0.09123445,\n        0.19223225, 0.7020471 , 0.9399637 , 0.19870114],\n       [0.9222454 , 0.5660691 , 0.2424972 , 0.67506707, 0.30953145,\n        0.6818143 , 0.8776636 , 0.03674424, 0.05496967],\n       [0.17781079, 0.5663899 , 0.8069583 , 0.22616959, 0.06723011,\n        0.6656265 , 0.15640712, 0.6028372 , 0.06410778],\n       [0.8404925 , 0.41855812, 0.07419991, 0.3798039 , 0.1709181 ,\n        0.13665378, 0.46457303, 0.04188311, 0.8394971 ],\n       [0.08059514, 0.9196471 , 0.8023145 , 0.2743758 , 0.4729755 ,\n        0.60347533, 0.70600677, 0.483505  , 0.26264012],\n       [0.61654353, 0.5198692 , 0.17046595, 0.05148172, 0.20338058,\n        0.8321955 , 0.53042686, 0.896618  , 0.58778095],\n       [0.54212296, 0.26471233, 0.6563455 , 0.81151223, 0.87764883,\n        0.37578297, 0.6802931 , 0.735088  , 0.5409715 ],\n       [0.8927363 , 0.74577737, 0.40862393, 0.9608593 , 0.5893332 ,\n        0.34054184, 0.07919669, 0.933022  , 0.60402036],\n       [0.47236383, 0.43862855, 0.77626085, 0.24009776, 0.00291228,\n        0.5353006 , 0.97053874, 0.59289396, 0.8790935 ]], dtype=float32)>), (None, <tf.Variable 'Variable:0' shape=(6, 9) dtype=float32, numpy=\narray([[0.70982015, 0.27539325, 0.6011385 , 0.07611561, 0.9435061 ,\n        0.5364251 , 0.72496164, 0.38103282, 0.58070695],\n       [0.96982956, 0.03967583, 0.5653516 , 0.17442071, 0.7998333 ,\n        0.2827803 , 0.5764619 , 0.33283865, 0.6365974 ],\n       [0.01781499, 0.68678486, 0.5397886 , 0.9713186 , 0.04312575,\n        0.20271134, 0.1596967 , 0.4220227 , 0.4085616 ],\n       [0.52900815, 0.821771  , 0.9354985 , 0.7797735 , 0.09302151,\n        0.9428786 , 0.8968643 , 0.57245517, 0.51524746],\n       [0.01930261, 0.47409034, 0.24466646, 0.19588721, 0.68170893,\n        0.08301294, 0.07731783, 0.05730796, 0.7885418 ],\n       [0.7355459 , 0.8096719 , 0.18366814, 0.38870835, 0.09822619,\n        0.7393323 , 0.6929877 , 0.24453783, 0.74897826]], dtype=float32)>), (None, <tf.Variable 'Variable:0' shape=(9,) dtype=float32, numpy=array([1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>))."
     ]
    }
   ],
   "source": [
    "n_ciclics, n_rows, n_features = X.shape\n",
    "epochs = 1\n",
    "lr = 0.01\n",
    "model = MarketAI([\n",
    "    RNNLayer(n_rows, n_features, n_features)\n",
    "], epochs, lr)\n",
    "model.train(X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1cce27c8212bf6c5aa96f33a3d1153887721b66c5c8cb9adeaa83cce09196b75"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
