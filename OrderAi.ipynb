{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.python.ops.numpy_ops import np_config\n",
    "np_config.enable_numpy_behavior()\n",
    "\n",
    "housing = fetch_california_housing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "ename": "ResourceExhaustedError",
     "evalue": "{{function_node __wrapped__Sigmoid_device_/job:localhost/replica:0/task:0/device:CPU:0}} OOM when allocating tensor with shape[17544,17544] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu [Op:Sigmoid]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[63], line 35\u001b[0m\n\u001b[0;32m     32\u001b[0m X_train, X_test, y_train, y_test \u001b[39m=\u001b[39m train_test_split(housing\u001b[39m.\u001b[39mdata, housing\u001b[39m.\u001b[39mtarget, test_size\u001b[39m=\u001b[39m\u001b[39m0.15\u001b[39m)\n\u001b[0;32m     34\u001b[0m model \u001b[39m=\u001b[39m MLPLinearRegressor()\n\u001b[1;32m---> 35\u001b[0m model\u001b[39m.\u001b[39;49minitialize(X_train, y_train)\n\u001b[0;32m     36\u001b[0m model\u001b[39m.\u001b[39mtrain()\n",
      "Cell \u001b[1;32mIn[63], line 23\u001b[0m, in \u001b[0;36mMLPLinearRegressor.initialize\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mactivation\u001b[39m.\u001b[39mwrite(l\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, [tf\u001b[39m.\u001b[39mmath\u001b[39m.\u001b[39msigmoid(tf\u001b[39m.\u001b[39mtensordot(X, tf\u001b[39m.\u001b[39mtranspose(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mweights[l\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m][n]), \u001b[39m1\u001b[39m)) \u001b[39mfor\u001b[39;00m n \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_neurons)])\u001b[39m.\u001b[39mmark_used()\n\u001b[0;32m     22\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 23\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mactivation\u001b[39m.\u001b[39mwrite(l, [tf\u001b[39m.\u001b[39mmath\u001b[39m.\u001b[39msigmoid(tf\u001b[39m.\u001b[39mtensordot(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mweights[l\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m][n], tf\u001b[39m.\u001b[39mtranspose(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mweights[l][n]), \u001b[39m1\u001b[39m)) \u001b[39mfor\u001b[39;00m n \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_neurons)])\u001b[39m.\u001b[39mmark_used()\n\u001b[0;32m     26\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minitialized \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[63], line 23\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mactivation\u001b[39m.\u001b[39mwrite(l\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, [tf\u001b[39m.\u001b[39mmath\u001b[39m.\u001b[39msigmoid(tf\u001b[39m.\u001b[39mtensordot(X, tf\u001b[39m.\u001b[39mtranspose(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mweights[l\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m][n]), \u001b[39m1\u001b[39m)) \u001b[39mfor\u001b[39;00m n \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_neurons)])\u001b[39m.\u001b[39mmark_used()\n\u001b[0;32m     22\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 23\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mactivation\u001b[39m.\u001b[39mwrite(l, [tf\u001b[39m.\u001b[39;49mmath\u001b[39m.\u001b[39;49msigmoid(tf\u001b[39m.\u001b[39;49mtensordot(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweights[l\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m][n], tf\u001b[39m.\u001b[39;49mtranspose(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweights[l][n]), \u001b[39m1\u001b[39;49m)) \u001b[39mfor\u001b[39;00m n \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_neurons)])\u001b[39m.\u001b[39mmark_used()\n\u001b[0;32m     26\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minitialized \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m--> 153\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m    154\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    155\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\framework\\ops.py:7215\u001b[0m, in \u001b[0;36mraise_from_not_ok_status\u001b[1;34m(e, name)\u001b[0m\n\u001b[0;32m   7213\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mraise_from_not_ok_status\u001b[39m(e, name):\n\u001b[0;32m   7214\u001b[0m   e\u001b[39m.\u001b[39mmessage \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (\u001b[39m\"\u001b[39m\u001b[39m name: \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m name \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m-> 7215\u001b[0m   \u001b[39mraise\u001b[39;00m core\u001b[39m.\u001b[39m_status_to_exception(e) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: {{function_node __wrapped__Sigmoid_device_/job:localhost/replica:0/task:0/device:CPU:0}} OOM when allocating tensor with shape[17544,17544] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu [Op:Sigmoid]"
     ]
    }
   ],
   "source": [
    "class MLPLinearRegressor(object):\n",
    "    def __init__(self, lr=0.001, n_layers=3, n_neurons=3):\n",
    "        self.lr = 0.001\n",
    "        self.n_layers = n_layers\n",
    "        self.n_neurons = n_neurons\n",
    "        self.initialized = False\n",
    "\n",
    "    \n",
    "\n",
    "    def initialize(self, X, y):\n",
    "        n_samples, n_features = X.shape\n",
    "        normal_initiliazer = tf.random_normal_initializer(seed=0, mean=0.0, stddev=1.0)\n",
    "        XN = tf.keras.utils.normalize(X)\n",
    "        self.X = tf.constant(XN, name=\"X\", dtype=tf.float32)\n",
    "        self.y = tf.constant(np.array(y).reshape(-1, 1), name=\"y\", dtype=tf.float32)\n",
    "        self.weights = tf.Variable(normal_initiliazer((self.n_layers, self.n_neurons, n_samples, n_features), dtype=tf.float32), name=\"weights\", dtype=tf.float32)\n",
    "        self.bias = tf.Variable(np.zeros(self.n_layers), name=\"bias\", dtype=tf.float32)\n",
    "        self.activation = tf.TensorArray(tf.float32, size=self.n_layers, dynamic_size=True, clear_after_read=False)\n",
    "        for l in range(self.n_layers):\n",
    "            if l-1 == 0:\n",
    "                self.activation.write(l-1, [tf.math.sigmoid(tf.tensordot(X, tf.transpose(self.weights[l-1][n]), 1)) for n in range(self.n_neurons)]).mark_used()\n",
    "            else:\n",
    "                self.activation.write(l, [tf.math.sigmoid(tf.tensordot(self.weights[l-1][n], tf.transpose(self.weights[l][n]), 1)) for n in range(self.n_neurons)]).mark_used()\n",
    "\n",
    "\n",
    "        self.initialized = True\n",
    "\n",
    "    def train(self):\n",
    "        if self.initialized:\n",
    "            pass\n",
    "            \n",
    "X_train, X_test, y_train, y_test = train_test_split(housing.data, housing.target, test_size=0.15)\n",
    "\n",
    "model = MLPLinearRegressor()\n",
    "model.initialize(X_train, y_train)\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1cce27c8212bf6c5aa96f33a3d1153887721b66c5c8cb9adeaa83cce09196b75"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
